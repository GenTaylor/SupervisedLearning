{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Challenge: Feedback analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules and potential modules\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import nltk\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the Amazon review dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/GenTaylor/unit2/master/amazon_cells_labelled.txt', delimiter= '\\t', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving the columns names\n",
    "data.columns = ['review', 'number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  number\n",
       "0  So there is no way for me to plug it in here i...       0\n",
       "1                        Good case, Excellent value.       1\n",
       "2                             Great for the jawbone.       1\n",
       "3  Tied to charger for conversations lasting more...       0\n",
       "4                                  The mic is great.       1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVectorizer\n",
    "stopset = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=stopset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting text to features\n",
    "reviewed = vectorizer.fit_transform(data.review)\n",
    "\n",
    "#dependent variable result 0 = bad 1=good\n",
    "result = data.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test train setup\n",
    "reviewed_train,  reviewed_test, results_train, results_test = train_test_split(reviewed, result, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train naive bayes\n",
    "clf = naive_bayes.MultinomialNB()\n",
    "clf.fit(reviewed_train, results_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057203389830508"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test accuracy\n",
    "roc_auc_score(results_test, clf.predict_proba(reviewed_test) [:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#testing statement from amazon dataset\n",
    "reviews_array=np.array([\"Needless to say, I wasted my money\"])\n",
    "reviews_vector=vectorizer.transform(reviews_array)\n",
    "print(clf.predict(reviews_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#test against another dataset from the file\n",
    "#First I took some text from the IMDB dataset to see would it work. \n",
    "#I wasn't 100% sure exactly how to do this, do I import of just copy.\n",
    "\n",
    "reviews_array=np.array([\"Loved the casting of Jimmy Buffet as the science teacher.  \t\"])\n",
    "reviews_vector=vectorizer.transform(reviews_array)\n",
    "print(clf.predict(reviews_vector))\n",
    "\n",
    "\n",
    "#checked as positive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decided to import the imdb dataset\n",
    "imdbdata = pd.read_csv('https://raw.githubusercontent.com/GenTaylor/unit2/master/imdb_labelled.txt', delimiter= '\\t', header = None)\n",
    "\n",
    "#giving the columns names\n",
    "imdbdata.columns = ['review', 'number']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#converting text to features\n",
    "imdbreviewed = vectorizer.fit_transform(data.review)\n",
    "\n",
    "#dependent variable result 0 = bad 1=good\n",
    "imdbresult = data.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9840949820788529"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test accuracy\n",
    "roc_auc_score(imdbresults_test, clf.predict_proba(imdbreviewed_test) [:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test train setup\n",
    "imdbreviewed_train,  imdbreviewed_test, imdbresults_train, imdbresults_test = train_test_split(imdbreviewed, imdbresult, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test train setup\n",
    "imdbreviewed_train,  imdbreviewed_test, imdbresults_train, imdbresults_test = train_test_split(imdbreviewed, imdbresult, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#testing statement from imdb dataset\n",
    "imdbreviews_array=np.array([\"Waste your money on this game\"])\n",
    "imdbreviews_vector=vectorizer.transform(imdbreviews_array)\n",
    "print(clf.predict(imdbreviews_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The NB test seemed more accurate against the IMDB dataset than the Amazon dataset.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For this challenge and dataset I decided to use a MultinomialNB for the text classification exercise. The reason that I chose this as a method was because of how I saw it defined. MultinomialNB is a probabilistic learning method that means that the probability of d (or reviews) being in a class (result). </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Genesis Taylor </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
