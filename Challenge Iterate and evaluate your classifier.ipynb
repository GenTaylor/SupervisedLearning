{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Challenge: Iterate and evaluate your classifier</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to revisit your classifier from the previous assignment. Using the evaluation techniques we've covered here, look at your classifier's performance in more detail. Then go back and iterate by engineering new features, removing poor features, or tuning parameters. Repeat this process until you have five different versions of your classifier. Once you've iterated, answer these questions to compare the performance of each:\n",
    "\n",
    "Do any of your classifiers seem to overfit?\n",
    "Which seem to perform the best? Why?\n",
    "Which features seemed to be most impactful to performance?\n",
    "\n",
    "Write up your iterations and answers to the above questions in a few pages. Submit a link below and go over it with your mentor to see if they have any other ideas on how you could improve your classifier's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules and potential modules\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import nltk\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFdr, chi2\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the Amazon review dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/GenTaylor/unit2/master/amazon_cells_labelled.txt', delimiter= '\\t', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving the columns names\n",
    "df.columns = ['review', 'number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  number\n",
       "0  So there is no way for me to plug it in here i...       0\n",
       "1                        Good case, Excellent value.       1\n",
       "2                             Great for the jawbone.       1\n",
       "3  Tied to charger for conversations lasting more...       0\n",
       "4                                  The mic is great.       1"
      ]
     },
     "execution_count": 935,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  number\n",
       "995  The screen does get smudged easily because it ...       0\n",
       "996  What a piece of junk.. I lose more calls on th...       0\n",
       "997                       Item Does Not Match Picture.       0\n",
       "998  The only thing that disappoint me is the infra...       0\n",
       "999  You can not answer calls with the unit, never ...       0"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: number, dtype: int64"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "#0=negative 1=positive\n",
    "df.number.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y for use with COUNTVECTORIZER\n",
    "\n",
    "X = df.review\n",
    "y = df.number\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750,)\n",
      "(250,)\n",
      "(750,)\n",
      "(250,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<750x1541 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6874 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<250x1541 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1914 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>First we used MultinomialNB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a Multinomial Naive Bayes model\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm \n",
    "mnb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = mnb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 96,  36],\n",
       "       [ 16, 102]], dtype=int64)"
      ]
     },
     "execution_count": 949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142                      I was not happy with this item.\n",
       "108    The camera, although rated at an impressive 1....\n",
       "90     For a product that costs as much as this one d...\n",
       "453    I even fully charged it before I went to bed a...\n",
       "639    Disappointing accessory from a good manufacturer.\n",
       "885    When it opens, the battery connection is broke...\n",
       "307    As many people complained, I found this headse...\n",
       "734    We have tried 2 units and they both failed wit...\n",
       "528                                 No real improvement.\n",
       "992                     Lasted one day and then blew up.\n",
       "559                 None of it works, just don't buy it.\n",
       "154    I've bought $5 wired headphones that sound bet...\n",
       "868                   The item received was Counterfeit.\n",
       "794    The internet access was fine, it the rare inst...\n",
       "311                   The instruction manual is lacking.\n",
       "799    I tried talking real loud but shouting on the ...\n",
       "625                      Very Dissapointing Performance.\n",
       "248                     Internet is excrutiatingly slow.\n",
       "358                        The phone gets EXTREMELY HOT!\n",
       "555                                    It's AGGRAVATING!\n",
       "354                  Excellent starter wireless headset.\n",
       "576             The battery life is highly unacceptable.\n",
       "84     This item worked great, but it broke after 6 m...\n",
       "244       It defeats the purpose of a bluetooth headset.\n",
       "202    It makes very strange ticking noises before it...\n",
       "81                                   Not a good bargain.\n",
       "314    The battery is unreliable as well as the servi...\n",
       "826                          Not as good as I had hoped.\n",
       "608     It is cheap, and it feel and look just as cheap.\n",
       "382               Same problem as others have mentioned.\n",
       "675           Can't upload ringtones from a third party.\n",
       "355    The loudspeaker option is great, the bumpers w...\n",
       "99               I'm very disappointed with my decision.\n",
       "833    My father has the V265, and the battery is dying.\n",
       "181    I've had this bluetoooth headset for some time...\n",
       "890    The speaker is of low quality so as making the...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the negative incorrectly classified as positive\n",
    "X_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600    Their Research and Development division obviou...\n",
       "721    My phone doesn't slide around my car now and t...\n",
       "537    Small, sleek, impressive looking, practical se...\n",
       "34     Car charger as well as AC charger are included...\n",
       "956    Just reading on the specs alone makes you say ...\n",
       "911    So I bought about 10 of these and saved alot o...\n",
       "512    The sound is clear and the people I talk to on...\n",
       "159                                W810i is just SUPERB.\n",
       "797    A good quality bargain.. I bought this after I...\n",
       "443           Restored my phone to like new performance.\n",
       "578    It does everything the description said it would.\n",
       "699    Comfortable fit - you need your headset to be ...\n",
       "429    My Sanyo has survived dozens of drops on black...\n",
       "945    It is easy to turn on and off when you are in ...\n",
       "301              Now I know that I made a wise decision.\n",
       "474                            The delivery was on time.\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the positives incorrectly classified as negative\n",
    "X_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The delivery was on time.'"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example false negative\n",
    "X_test[474]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01249421e-01, 1.59691980e-01, 9.99590149e-01, 9.38768598e-01,\n",
       "       1.10011416e-02, 2.38536973e-01, 9.99332483e-01, 1.46480394e-01,\n",
       "       1.21092819e-02, 2.43815666e-01, 8.56946008e-02, 7.01233381e-01,\n",
       "       1.36199605e-03, 9.88800911e-01, 9.74630257e-01, 7.78014357e-01,\n",
       "       3.74553508e-01, 3.73808381e-02, 9.69520797e-02, 9.83575217e-01,\n",
       "       6.07787946e-01, 1.18083722e-03, 9.82459893e-01, 1.13440926e-01,\n",
       "       9.84675604e-01, 8.11570485e-01, 7.84398051e-01, 9.74985926e-01,\n",
       "       9.92767240e-03, 8.68460079e-02, 9.51402836e-01, 9.66162789e-01,\n",
       "       7.01838147e-03, 8.80009625e-02, 3.61780421e-03, 2.90891608e-01,\n",
       "       9.99555431e-01, 9.30543429e-02, 1.03872153e-03, 3.77459020e-02,\n",
       "       7.05493240e-01, 8.28459721e-01, 9.87477996e-01, 1.22254776e-03,\n",
       "       2.34752697e-03, 2.35537072e-01, 4.45437474e-01, 1.80334884e-01,\n",
       "       5.45106235e-01, 4.79577998e-02, 8.68086072e-01, 1.33103427e-01,\n",
       "       6.78055325e-01, 7.91211096e-03, 2.90573208e-01, 1.89659532e-01,\n",
       "       5.64156020e-01, 2.55734991e-01, 4.86710845e-01, 7.82021525e-01,\n",
       "       7.16057854e-01, 5.70070658e-01, 6.29457508e-01, 8.65791466e-01,\n",
       "       9.96949270e-01, 6.82007211e-01, 4.65615482e-01, 8.76475254e-01,\n",
       "       5.77143506e-01, 9.75935968e-01, 6.48197724e-01, 4.24629334e-01,\n",
       "       1.31302386e-01, 9.19588073e-01, 9.86613639e-01, 1.57658021e-02,\n",
       "       9.47616095e-01, 6.44511557e-02, 9.24982157e-01, 9.97805195e-01,\n",
       "       1.10231724e-01, 6.84042999e-02, 9.95173470e-01, 4.00678065e-01,\n",
       "       3.75918499e-01, 5.91002004e-01, 1.46614757e-01, 3.47681431e-03,\n",
       "       9.50867612e-01, 8.03937479e-01, 4.26611660e-02, 1.06002234e-02,\n",
       "       9.99801879e-01, 4.57337754e-01, 3.87315514e-02, 6.79881670e-02,\n",
       "       6.09972401e-01, 6.26434745e-01, 9.95021726e-01, 7.34516440e-01,\n",
       "       9.95585956e-02, 9.05742819e-01, 9.23851530e-02, 5.75401863e-01,\n",
       "       7.29952083e-01, 3.20568565e-01, 9.82811913e-01, 8.72161070e-01,\n",
       "       9.72344937e-01, 6.30126879e-02, 2.33724820e-01, 1.36357541e-02,\n",
       "       5.04099584e-01, 2.31645484e-02, 6.22885918e-01, 9.16541648e-01,\n",
       "       1.56434534e-01, 2.91562220e-01, 9.97166279e-01, 9.70657140e-01,\n",
       "       1.89780350e-01, 5.77489416e-01, 4.37124573e-01, 2.96111050e-01,\n",
       "       9.99747823e-01, 9.83038220e-01, 9.92263500e-01, 5.37568308e-02,\n",
       "       5.19855921e-01, 7.31602744e-01, 7.80032523e-01, 5.82672263e-01,\n",
       "       2.32470155e-01, 9.92299396e-01, 6.28048209e-02, 9.33717580e-02,\n",
       "       9.74512617e-01, 9.75563508e-01, 8.33805633e-01, 8.39244371e-01,\n",
       "       9.54062538e-01, 8.61834921e-01, 8.84066986e-01, 4.94970491e-01,\n",
       "       9.92120948e-01, 3.26950520e-01, 3.19258428e-01, 8.97842579e-03,\n",
       "       5.07588627e-01, 5.40880597e-01, 9.94073284e-01, 6.28318349e-03,\n",
       "       1.06339706e-01, 6.08285194e-02, 2.65193624e-01, 9.16824421e-01,\n",
       "       9.73585253e-01, 6.33487425e-01, 6.72829092e-01, 3.71976497e-01,\n",
       "       4.65989945e-01, 9.97508634e-01, 9.58389085e-01, 1.07137256e-02,\n",
       "       8.97741367e-01, 9.63650439e-01, 8.91272607e-01, 9.82229752e-01,\n",
       "       4.37294835e-02, 5.09771284e-01, 5.77121032e-01, 7.99789990e-01,\n",
       "       9.38768598e-01, 4.42802717e-01, 3.79130669e-01, 7.17842520e-01,\n",
       "       2.26288740e-01, 9.24286725e-01, 9.99360918e-01, 5.05843736e-01,\n",
       "       7.74661241e-01, 1.69368644e-02, 8.62507146e-02, 2.72028490e-03,\n",
       "       3.36234721e-01, 7.57879828e-01, 9.59169480e-01, 3.31364535e-01,\n",
       "       2.52305375e-01, 5.15140397e-02, 2.62239819e-01, 7.19821555e-01,\n",
       "       9.87880264e-01, 6.24107186e-01, 2.38747064e-01, 7.55648605e-01,\n",
       "       9.02084257e-01, 9.99476169e-01, 9.50250693e-01, 9.96795679e-01,\n",
       "       6.25570181e-01, 2.05791729e-01, 2.34752697e-03, 2.04227556e-02,\n",
       "       9.39185244e-01, 5.72740108e-01, 1.39188504e-02, 5.85451307e-03,\n",
       "       9.82412502e-01, 6.98705128e-01, 7.78519970e-01, 9.98086802e-01,\n",
       "       5.18520212e-04, 4.74675569e-01, 8.59881520e-01, 5.57096458e-01,\n",
       "       9.95534616e-01, 1.24689881e-01, 2.46575795e-02, 5.79164555e-02,\n",
       "       2.75876394e-02, 9.96664618e-01, 2.74954614e-01, 8.25840435e-01,\n",
       "       8.25899477e-01, 9.26162430e-01, 9.99995312e-01, 9.88733940e-01,\n",
       "       1.53744574e-04, 1.55595437e-01, 5.10124735e-01, 9.89184453e-01,\n",
       "       7.76542813e-01, 3.39856010e-01, 9.98106244e-01, 9.99900673e-01,\n",
       "       9.62936150e-01, 3.96528468e-01, 8.65480144e-01, 3.82750833e-01,\n",
       "       8.04084387e-01, 8.69179974e-01, 9.95229577e-01, 8.04812893e-01,\n",
       "       2.20159999e-01, 1.04539690e-03, 9.68939915e-01, 1.70623403e-04,\n",
       "       3.27209972e-01, 9.99973363e-01])"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = mnb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8744863893168977"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    132\n",
      "1    118\n",
      "Name: number, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# examine class distribution\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 0    0.528\n",
      "Name: number, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#calculate null accuracy (for multi-class classification problems)\n",
    "# .head(1) assesses the value 1208\n",
    "null_accuracy = y_test.value_counts().head(1) / len(y_test)\n",
    "print('Null accuracy:', null_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual null accuracy: 0.528\n"
     ]
    }
   ],
   "source": [
    "# Manual calculation of null accuracy by always predicting the majority class\n",
    "print('Manual null accuracy:',(132 / (132 + 118)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature selection SelectPercentile</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_selected is : (750, 770)\n"
     ]
    }
   ],
   "source": [
    "#feature selection SelectPercentile @ 50%\n",
    "\n",
    "select = SelectPercentile(percentile=50)\n",
    "select.fit(X_train_dtm, y_train)\n",
    "X_train_selected = select.transform(X_train_dtm)\n",
    "\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_selected is : {}'.format(X_train_selected.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.796\n"
     ]
    }
   ],
   "source": [
    "X_test_selected = select.transform(X_test_dtm)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logreg.score(X_test_dtm, y_test)))\n",
    "\n",
    "logreg.fit(X_train_selected, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logreg.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_selected is : (750, 308)\n"
     ]
    }
   ],
   "source": [
    "#feature selection SelectPercentile @ 20%\n",
    "\n",
    "select = SelectPercentile(percentile=20)\n",
    "select.fit(X_train_dtm, y_train)\n",
    "X_train_selected = select.transform(X_train_dtm)\n",
    "\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_selected is : {}'.format(X_train_selected.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.800\n"
     ]
    }
   ],
   "source": [
    "X_test_selected = select.transform(X_test_dtm)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logreg.score(X_test_dtm, y_test)))\n",
    "\n",
    "logreg.fit(X_train_selected, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logreg.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_selected is : (750, 1386)\n"
     ]
    }
   ],
   "source": [
    "#feature selection SelectPercentile @ 90%\n",
    "\n",
    "select = SelectPercentile(percentile=90)\n",
    "select.fit(X_train_dtm, y_train)\n",
    "X_train_selected = select.transform(X_train_dtm)\n",
    "\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_selected is : {}'.format(X_train_selected.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.816\n"
     ]
    }
   ],
   "source": [
    "X_test_selected = select.transform(X_test_dtm)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logreg.score(X_test_dtm, y_test)))\n",
    "\n",
    "logreg.fit(X_train_selected, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logreg.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature selection SelectKBest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_selectedk is : (750, 20)\n"
     ]
    }
   ],
   "source": [
    "#feature selection selectkbest k=20\n",
    "selectk = SelectKBest(chi2, k=20)\n",
    "selectk.fit(X_train_dtm, y_train)\n",
    "X_train_selectedk = selectk.transform(X_train_dtm)\n",
    "\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_selectedk is : {}'.format(X_train_selectedk.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.696\n"
     ]
    }
   ],
   "source": [
    "X_test_selectedk = selectk.transform(X_test_dtm)\n",
    "logregk = LogisticRegression()\n",
    "logregk.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logregk.score(X_test_dtm, y_test)))\n",
    "\n",
    "logregk.fit(X_train_selectedk, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logregk.score(X_test_selectedk, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_selectedk is : (750, 10)\n"
     ]
    }
   ],
   "source": [
    "#feature selection selectkbest k=10\n",
    "selectk = SelectKBest(chi2, k=10)\n",
    "selectk.fit(X_train_dtm, y_train)\n",
    "X_train_selectedk = selectk.transform(X_train_dtm)\n",
    "\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_selectedk is : {}'.format(X_train_selectedk.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.672\n"
     ]
    }
   ],
   "source": [
    "X_test_selectedk = selectk.transform(X_test_dtm)\n",
    "logregk = LogisticRegression()\n",
    "logregk.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logregk.score(X_test_dtm, y_test)))\n",
    "\n",
    "logregk.fit(X_train_selectedk, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logregk.score(X_test_selectedk, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_selectedk is : (750, 40)\n"
     ]
    }
   ],
   "source": [
    "#feature selection selectkbest k=40\n",
    "selectk = SelectKBest(chi2, k=40)\n",
    "selectk.fit(X_train_dtm, y_train)\n",
    "X_train_selectedk = selectk.transform(X_train_dtm)\n",
    "\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_selectedk is : {}'.format(X_train_selectedk.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.712\n"
     ]
    }
   ],
   "source": [
    "X_test_selectedk = selectk.transform(X_test_dtm)\n",
    "logregk = LogisticRegression()\n",
    "logregk.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logregk.score(X_test_dtm, y_test)))\n",
    "\n",
    "logregk.fit(X_train_selectedk, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logregk.score(X_test_selectedk, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature selection SelectFdr</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_sfdr is : (750, 6)\n"
     ]
    }
   ],
   "source": [
    "#Feature SelectFdr alpha @ 0.01\n",
    "sfdr = SelectFdr(chi2, alpha=0.01)\n",
    "sfdr.fit(X_train_dtm, y_train)\n",
    "X_train_sfdr = sfdr.transform(X_train_dtm)\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_sfdr is : {}'.format(X_train_sfdr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.628\n"
     ]
    }
   ],
   "source": [
    "X_test_sfdr = sfdr.transform(X_test_dtm)\n",
    "logregk = LogisticRegression()\n",
    "logregk.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logregk.score(X_test_dtm, y_test)))\n",
    "\n",
    "logregk.fit(X_train_sfdr, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logregk.score(X_test_sfdr, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_sfdr is : (750, 1293)\n"
     ]
    }
   ],
   "source": [
    "#Feature SelectFdr alpha @ 0.5\n",
    "sfdr = SelectFdr(chi2, alpha=0.5)\n",
    "sfdr.fit(X_train_dtm, y_train)\n",
    "X_train_sfdr = sfdr.transform(X_train_dtm)\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_sfdr is : {}'.format(X_train_sfdr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.816\n"
     ]
    }
   ],
   "source": [
    "X_test_sfdr = sfdr.transform(X_test_dtm)\n",
    "logregk = LogisticRegression()\n",
    "logregk.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logregk.score(X_test_dtm, y_test)))\n",
    "\n",
    "logregk.fit(X_train_sfdr, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logregk.score(X_test_sfdr, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_sfdr is : (750, 21)\n"
     ]
    }
   ],
   "source": [
    "#Feature SelectFdr alpha @ 0.2\n",
    "sfdr = SelectFdr(chi2, alpha=0.2)\n",
    "sfdr.fit(X_train_dtm, y_train)\n",
    "X_train_sfdr = sfdr.transform(X_train_dtm)\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_sfdr is : {}'.format(X_train_sfdr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.692\n"
     ]
    }
   ],
   "source": [
    "X_test_sfdr = sfdr.transform(X_test_dtm)\n",
    "logregk = LogisticRegression()\n",
    "logregk.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logregk.score(X_test_dtm, y_test)))\n",
    "\n",
    "logregk.fit(X_train_sfdr, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logregk.score(X_test_sfdr, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature selection Variance Threshold</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_vt is : (750, 1541)\n"
     ]
    }
   ],
   "source": [
    "#Variance Threshold w 0 variance\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "vt.fit(X_train_dtm, y_train)\n",
    "X_train_vt = vt.transform(X_train_dtm)\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_vt is : {}'.format(X_train_vt.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.796\n"
     ]
    }
   ],
   "source": [
    "#Variance Threshold w 0 variance\n",
    "X_test_vt = vt.transform(X_test_dtm)\n",
    "logregk = LogisticRegression()\n",
    "logregk.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logregk.score(X_test_dtm, y_test)))\n",
    "\n",
    "logregk.fit(X_train_vt, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logregk.score(X_test_vt, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_vt is : (750, 13)\n"
     ]
    }
   ],
   "source": [
    "#Variance Threshold w 0.1 variance\n",
    "vt = VarianceThreshold(threshold=0.1)\n",
    "vt.fit(X_train_dtm, y_train)\n",
    "X_train_vt = vt.transform(X_train_dtm)\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_vt is : {}'.format(X_train_vt.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.628\n"
     ]
    }
   ],
   "source": [
    "#Variance Threshold w 0.1 variance\n",
    "X_test_vt = vt.transform(X_test_dtm)\n",
    "logregk = LogisticRegression()\n",
    "logregk.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logregk.score(X_test_dtm, y_test)))\n",
    "\n",
    "logregk.fit(X_train_vt, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logregk.score(X_test_vt, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dtm.shape is : (750, 1541)\n",
      "X_train_vt is : (750, 1)\n"
     ]
    }
   ],
   "source": [
    "#Variance Threshold w 0.5 variance\n",
    "vt = VarianceThreshold(threshold=0.5)\n",
    "vt.fit(X_train_dtm, y_train)\n",
    "X_train_vt = vt.transform(X_train_dtm)\n",
    "print('X_train_dtm.shape is : {}'.format(X_train_dtm.shape))\n",
    "print('X_train_vt is : {}'.format(X_train_vt.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of Logistic Regression on all features: 0.796\n",
      "The score of Logistic Regression on the selected features: 0.536\n"
     ]
    }
   ],
   "source": [
    "#Variance Threshold w 0.5 variance\n",
    "X_test_vt = vt.transform(X_test_dtm)\n",
    "logregk = LogisticRegression()\n",
    "logregk.fit(X_train_dtm, y_train)\n",
    "\n",
    "print('The score of Logistic Regression on all features: {:.3f}'.format(logregk.score(X_test_dtm, y_test)))\n",
    "\n",
    "logregk.fit(X_train_vt, y_train)\n",
    "print('The score of Logistic Regression on the selected features: {:.3f}'.format(logregk.score(X_test_vt, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Summary</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Below you will find the accuracy scores of the features and methods used:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MultinomialNB:</b> \n",
    "-  metrics.accuracy_score = 0.792\n",
    "-  metrics.roc_auc_score = 0.8744\n",
    "-  null_accuracy = 0.528\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>With ALL selected the scores of the following under logistic regression was 0.796. The scores below are with certain parameters set.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SelectPercentile:</b>\n",
    "-  Score @ 50% Selected: 0.796\n",
    "-  Score @ 20% Selected: 0.800\n",
    "-  Score @ 90% Selected: 0.816\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SelectKBest:</b>\n",
    "-  Score w/ k=20: 0.696\n",
    "-  Score w/ k=10: 0.672\n",
    "-  Score w/ k=40: 0.712\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SelectFDR:</b>\n",
    "-  Score w alpha @ 0.01= 0.628\n",
    "-  Score w alpha @ 0.5: 0.816\n",
    "-  Score w alpha @ 0.2: 0.692\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>VarianceThreshold:</b>\n",
    "-  Score w. threshold=0: 0.796\n",
    "-  Score w. threshold = 0.1: 0.628\n",
    "-  Score w. threshold = 0.5: 0.536\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these different features I noticed patterns for all of them except SelectPercentile. For each of them, with a change in the numbers used, the score followed a trend of increasing or decreasing. With SelectPercentile, it varied by percentage leaving me to believe that it would cause an overfit. \n",
    "\n",
    "SelectKBest increased as k increased.\n",
    "SelectFDR increased as the alpha number increased.\n",
    "VarianceThreshold decreased as the threshold increased. \n",
    "\n",
    "SelectPercentile seemed to be the only one that had an issue or with the changes being made. It seemed to make things more unpredictable than the other features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
